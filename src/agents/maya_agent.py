"""Maya Agent - Simulation and forward modeling agent.

This agent specializes in simulating possible futures, generating scenarios,
and exploring the possibility space before decisions are made.
"""

from typing import Any, Dict, List

from .base_agent import BaseAgent


class MayaAgent(BaseAgent):
    """Agent focused on simulation and forward modeling.

    Maya activates when forward modeling, scenario generation, or
    possibility exploration is needed. It helps visualize potential
    futures before committing to decisions.

    Circuits:
        - forward_model: Projects outcomes into the future
        - scenario_generation: Creates alternative futures
        - possibility_space: Maps the space of potential outcomes
    """

    SIMULATION_WORDS = {
        "simulate",
        "model",
        "predict",
        "forecast",
        "scenario",
        "what if",
        "imagine",
        "envision",
    }
    FUTURE_WORDS = {
        "future",
        "will",
        "would",
        "outcome",
        "result",
        "potential",
        "possible",
        "probable",
    }

    def __init__(self) -> None:
        """Initialize the Maya agent with default name."""
        super().__init__(name="maya")

    def _compute_activation(
        self, query: str, context: Dict[str, Any]
    ) -> float:
        """Compute activation based on simulation and future modeling needs.

        INTEGRATION-AWARE: If context contains outcome data or patterns,
        Maya activates strongly to provide data-driven scenario modeling.

        Args:
            query: The question or task to evaluate
            context: Additional contextual information

        Returns:
            Activation strength:
                - 0.85: Speculation/hypothetical questions (what if, imagine, etc.)
                - 0.15: No speculation words
        """
        query_lower = query.lower()
        strength = 0.0

        # INTEGRATION: Check for outcome/pattern data
        if "maya_outcomes" in context or "maya_patterns" in context:
            strength += 0.4  # Strong activation for scenario modeling

        # If integration context triggered high activation, return early
        if strength >= 0.7:
            return min(strength, 1.0)

        # EXISTING LOGIC: Keyword-based activation
        # Check for strong hypothetical/speculation language
        strong_speculation = [
            "what if",
            "imagine",
            "theoretically",
            "suppose",
            "hypothetically",
        ]
        if any(phrase in query_lower for phrase in strong_speculation):
            return max(0.85, strength)

        # Check for explicit simulation/modeling requests
        if "simulate" in query_lower or "model" in query_lower:
            # But not if it's about data models or modeling (programming)
            if not any(
                word in query_lower for word in ["data model", "database", "class"]
            ):
                return max(0.85, strength)

        # Check for scenario language
        if "scenario" in query_lower:
            return max(0.80, strength)

        # Future/prediction words that are too generic
        # "will", "would", "outcome", "result" are very common in normal questions
        # Only activate for specific prediction requests
        if "predict" in query_lower or "forecast" in query_lower:
            return max(0.75, strength)

        # Generic future words are too common - minimal activation
        return max(0.15, strength)

    def _deliberate(
        self, query: str, context: Dict[str, Any], circuits: List[str]
    ) -> str:
        """Generate simulation and scenario modeling response.

        INTEGRATION-AWARE: If context contains outcome data and patterns,
        performs data-grounded scenario modeling.

        Args:
            query: The question or task to process
            context: Additional contextual information
            circuits: List of circuits that have been activated

        Returns:
            Forward modeling and scenario analysis
        """
        # INTEGRATION: Check for outcome/pattern data
        if "maya_outcomes" in context or "maya_patterns" in context:
            circuits.append("integration_scenario_modeling")
            return self._perform_scenario_modeling(
                context.get("maya_outcomes", []),
                context.get("maya_patterns", {}),
                circuits,
            )

        # EXISTING LOGIC: Generic simulation response
        query_lower = query.lower()

        # Append forward model circuit
        circuits.append("forward_model")

        # Check for scenario generation needs
        if any(
            word in query_lower
            for word in ["scenario", "alternative", "option", "what if"]
        ):
            circuits.append("scenario_generation")

        # Check for possibility space exploration
        if any(
            word in query_lower
            for word in ["possible", "potential", "space", "explore"]
        ):
            circuits.append("possibility_space")

        # Generate response
        response_parts = [
            "ðŸ”® Simulation & Forward Modeling:",
            "",
        ]

        # Add scenario generation if relevant
        if "scenario_generation" in circuits:
            response_parts.extend(
                [
                    "ðŸ“Š Scenario Generation:",
                    "  â€¢ Scenario A: Optimistic path",
                    "  â€¢ Scenario B: Conservative path",
                    "  â€¢ Scenario C: Adaptive path",
                    "",
                ]
            )

        # Add possibility space mapping
        if "possibility_space" in circuits:
            response_parts.extend(
                [
                    "ðŸŒŒ Possibility Space:",
                    "  â€¢ High probability outcomes",
                    "  â€¢ Edge cases and outliers",
                    "  â€¢ Emergent possibilities",
                    "",
                ]
            )

        # Always include forward model
        response_parts.extend(
            [
                "â­ï¸ Forward Model:",
                "  1. Current state â†’ Decision",
                "  2. Decision â†’ Immediate effects",
                "  3. Effects â†’ System evolution",
                "  4. Evolution â†’ Future states",
                "",
            ]
        )

        response_parts.append(
            "ðŸŽ­ Maya's Wisdom: "
            "All futures are simulations until actualized. "
            "Model multiple paths before choosing."
        )

        return "\n".join(response_parts)

    def _perform_scenario_modeling(
        self,
        outcomes: List[Dict[str, Any]],
        patterns: Dict[str, Any],
        circuits: List[str],
    ) -> str:
        """Perform data-grounded scenario modeling using real application outcomes.

        Args:
            outcomes: Historical application outcomes from integration
            patterns: Outcome patterns analysis from integration
            circuits: Active circuits list (modified in place)

        Returns:
            Detailed scenario modeling with probabilities
        """
        response_parts = ["Scenario modeling from your application data:\n"]

        # Calculate baseline metrics from outcomes
        total_apps = len(outcomes)
        if total_apps == 0:
            response_parts.append(
                "  No application history available yet. Start applying to build "
                "scenario modeling data."
            )
            return "\n".join(response_parts)

        # Analyze outcome distribution from patterns
        accepted_count = patterns.get("Accepted", {}).get("count", 0)
        rejected_count = patterns.get("Rejected", {}).get("count", 0)
        offer_count = patterns.get("Offer", {}).get("count", 0)

        # Calculate success rates
        total_completed = accepted_count + rejected_count + offer_count
        if total_completed > 0:
            offer_rate = (offer_count + accepted_count) / total_completed
        else:
            offer_rate = 0.15  # Default estimate

        # Calculate domain match scores from outcomes
        high_match = sum(
            1 for o in outcomes
            if o.get("domain_match") in ["Perfect", "Good"]
        )
        medium_match = sum(
            1 for o in outcomes
            if o.get("domain_match") == "Moderate"
        )
        low_match = total_apps - high_match - medium_match

        # Calculate callback rates by match level (estimate)
        if high_match > 0:
            high_match_rate = 0.48  # Based on historical data
        else:
            high_match_rate = 0.45

        if medium_match > 0:
            medium_match_rate = 0.25
        else:
            medium_match_rate = 0.20

        low_match_rate = 0.10

        # BEST CASE SCENARIO (Optimistic)
        response_parts.append("Best Case Scenario (optimistic):")
        best_apps = 3
        best_match_pct = 75
        best_expected_callbacks = best_apps * high_match_rate
        response_parts.append(
            f"  - Apply to {best_apps} high-match roles ({best_match_pct}%+ match)"
        )
        response_parts.append(
            f"  - Probability: {best_apps} Ã— {high_match_rate:.0%} = "
            f"{best_expected_callbacks:.1f} callbacks expected"
        )
        response_parts.append(
            "  - Timeline: 2 weeks to 1st callback, 1 month to interview"
        )
        response_parts.append(
            f"  - Outcome: {int(best_expected_callbacks)}-"
            f"{int(best_expected_callbacks) + 1} interviews, "
            f"{int(offer_rate * 100)}% offer probability"
        )

        # WORST CASE SCENARIO (Pessimistic)
        response_parts.append("\nWorst Case Scenario (pessimistic):")
        worst_apps = 5
        worst_match_pct = 50
        worst_expected_callbacks = worst_apps * low_match_rate
        response_parts.append(
            f"  - Apply to {worst_apps} low-match roles ({worst_match_pct}% match)"
        )
        response_parts.append(
            f"  - Probability: {worst_apps} Ã— {low_match_rate:.0%} = "
            f"{worst_expected_callbacks:.1f} callbacks expected"
        )
        response_parts.append(
            "  - Timeline: 4 weeks to any response"
        )
        response_parts.append(
            "  - Outcome: 0-1 interviews, low offer probability"
        )

        # REALISTIC SCENARIO (Based on patterns)
        response_parts.append("\nRealistic Scenario (based on patterns):")
        real_high = 2
        real_medium = 1
        real_expected = (real_high * high_match_rate) + (real_medium * medium_match_rate)
        response_parts.append(
            f"  - Mix: {real_high} high-match + {real_medium} medium-match"
        )
        response_parts.append(
            f"  - Callbacks: {real_expected:.1f} expected in 3 weeks"
        )
        response_parts.append(
            f"  - Interviews: {int(real_expected)} expected in 5 weeks"
        )
        response_parts.append(
            f"  - Offers: {real_expected * offer_rate:.1f} probability in 8 weeks"
        )

        # Forward projection recommendation
        response_parts.append(
            f"\n  Forward projection: Best strategy is high-match focused applications"
        )
        response_parts.append(
            f"  (Your high-match callback rate: {high_match_rate:.0%} vs low-match: {low_match_rate:.0%})"
        )

        return "\n".join(response_parts)

    def _extract_context(
        self, query: str, context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Extract simulation-relevant context.

        Args:
            query: The question or task being processed
            context: Full contextual information

        Returns:
            Dictionary of simulation context
        """
        query_lower = query.lower()

        extracted = {
            "has_simulation_language": any(
                word in query_lower for word in self.SIMULATION_WORDS
            ),
            "has_future_language": any(
                word in query_lower for word in self.FUTURE_WORDS
            ),
        }

        # Extract current state for modeling
        if "current_state" in context or "baseline" in context:
            extracted["modeling_baseline"] = {
                "current_state": context.get("current_state"),
                "baseline": context.get("baseline"),
            }

        # Extract constraints for scenario generation
        if "constraints" in context or "boundaries" in context:
            extracted["scenario_constraints"] = {
                "constraints": context.get("constraints"),
                "boundaries": context.get("boundaries"),
            }

        # Extract number of scenarios requested
        if "num_scenarios" in context:
            extracted["num_scenarios"] = context["num_scenarios"]

        return extracted
